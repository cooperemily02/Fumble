{"ast":null,"code":"'use strict';\n\nvar core = require('../core');\n\nvar crypto = require('crypto');\n\nvar stream = require('stream');\n\nvar util = require('util');\n\nvar Buffer = require('safe-buffer').Buffer;\n\nvar ERROR_NAMESPACE_NOT_FOUND = 26;\nmodule.exports = GridFSBucketWriteStream;\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n *\n * @class\n * @extends external:Writable\n * @param {GridFSBucket} bucket Handle for this stream's corresponding bucket\n * @param {string} filename The value of the 'filename' key in the files doc\n * @param {object} [options] Optional settings.\n * @param {string|number|object} [options.id] Custom file id for the GridFS file.\n * @param {number} [options.chunkSizeBytes] The chunk size to use, in bytes\n * @param {number} [options.w] The write concern\n * @param {number} [options.wtimeout] The write concern timeout\n * @param {number} [options.j] The journal write concern\n * @param {boolean} [options.disableMD5=false] If true, disables adding an md5 field to file data\n * @fires GridFSBucketWriteStream#error\n * @fires GridFSBucketWriteStream#finish\n */\n\nfunction GridFSBucketWriteStream(bucket, filename, options) {\n  options = options || {};\n  this.bucket = bucket;\n  this.chunks = bucket.s._chunksCollection;\n  this.filename = filename;\n  this.files = bucket.s._filesCollection;\n  this.options = options; // Signals the write is all done\n\n  this.done = false;\n  this.id = options.id ? options.id : core.BSON.ObjectId();\n  this.chunkSizeBytes = this.options.chunkSizeBytes;\n  this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n  this.length = 0;\n  this.md5 = !options.disableMD5 && crypto.createHash('md5');\n  this.n = 0;\n  this.pos = 0;\n  this.state = {\n    streamEnd: false,\n    outstandingRequests: 0,\n    errored: false,\n    aborted: false,\n    promiseLibrary: this.bucket.s.promiseLibrary\n  };\n\n  if (!this.bucket.s.calledOpenUploadStream) {\n    this.bucket.s.calledOpenUploadStream = true;\n\n    var _this = this;\n\n    checkIndexes(this, function () {\n      _this.bucket.s.checkedIndexes = true;\n\n      _this.bucket.emit('index');\n    });\n  }\n}\n\nutil.inherits(GridFSBucketWriteStream, stream.Writable);\n/**\n * An error occurred\n *\n * @event GridFSBucketWriteStream#error\n * @type {Error}\n */\n\n/**\n * `end()` was called and the write stream successfully wrote the file\n * metadata and all the chunks to MongoDB.\n *\n * @event GridFSBucketWriteStream#finish\n * @type {object}\n */\n\n/**\n * Write a buffer to the stream.\n *\n * @method\n * @param {Buffer} chunk Buffer to write\n * @param {String} encoding Optional encoding for the buffer\n * @param {GridFSBucket~errorCallback} callback Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n * @return {Boolean} False if this write required flushing a chunk to MongoDB. True otherwise.\n */\n\nGridFSBucketWriteStream.prototype.write = function (chunk, encoding, callback) {\n  var _this = this;\n\n  return waitForIndexes(this, function () {\n    return doWrite(_this, chunk, encoding, callback);\n  });\n};\n/**\n * Places this write stream into an aborted state (all future writes fail)\n * and deletes all chunks that have already been written.\n *\n * @method\n * @param {GridFSBucket~errorCallback} callback called when chunks are successfully removed or error occurred\n * @return {Promise} if no callback specified\n */\n\n\nGridFSBucketWriteStream.prototype.abort = function (callback) {\n  if (this.state.streamEnd) {\n    var error = new Error('Cannot abort a stream that has already completed');\n\n    if (typeof callback === 'function') {\n      return callback(error);\n    }\n\n    return this.state.promiseLibrary.reject(error);\n  }\n\n  if (this.state.aborted) {\n    error = new Error('Cannot call abort() on a stream twice');\n\n    if (typeof callback === 'function') {\n      return callback(error);\n    }\n\n    return this.state.promiseLibrary.reject(error);\n  }\n\n  this.state.aborted = true;\n  this.chunks.deleteMany({\n    files_id: this.id\n  }, function (error) {\n    if (typeof callback === 'function') callback(error);\n  });\n};\n/**\n * Tells the stream that no more data will be coming in. The stream will\n * persist the remaining data to MongoDB, write the files document, and\n * then emit a 'finish' event.\n *\n * @method\n * @param {Buffer} chunk Buffer to write\n * @param {String} encoding Optional encoding for the buffer\n * @param {GridFSBucket~errorCallback} callback Function to call when all files and chunks have been persisted to MongoDB\n */\n\n\nGridFSBucketWriteStream.prototype.end = function (chunk, encoding, callback) {\n  var _this = this;\n\n  if (typeof chunk === 'function') {\n    callback = chunk, chunk = null, encoding = null;\n  } else if (typeof encoding === 'function') {\n    callback = encoding, encoding = null;\n  }\n\n  if (checkAborted(this, callback)) {\n    return;\n  }\n\n  this.state.streamEnd = true;\n\n  if (callback) {\n    this.once('finish', function (result) {\n      callback(null, result);\n    });\n  }\n\n  if (!chunk) {\n    waitForIndexes(this, function () {\n      writeRemnant(_this);\n    });\n    return;\n  }\n\n  this.write(chunk, encoding, function () {\n    writeRemnant(_this);\n  });\n};\n/**\n * @ignore\n */\n\n\nfunction __handleError(_this, error, callback) {\n  if (_this.state.errored) {\n    return;\n  }\n\n  _this.state.errored = true;\n\n  if (callback) {\n    return callback(error);\n  }\n\n  _this.emit('error', error);\n}\n/**\n * @ignore\n */\n\n\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: core.BSON.ObjectId(),\n    files_id: filesId,\n    n: n,\n    data: data\n  };\n}\n/**\n * @ignore\n */\n\n\nfunction checkChunksIndex(_this, callback) {\n  _this.chunks.listIndexes().toArray(function (error, indexes) {\n    if (error) {\n      // Collection doesn't exist so create index\n      if (error.code === ERROR_NAMESPACE_NOT_FOUND) {\n        var index = {\n          files_id: 1,\n          n: 1\n        };\n\n        _this.chunks.createIndex(index, {\n          background: false,\n          unique: true\n        }, function (error) {\n          if (error) {\n            return callback(error);\n          }\n\n          callback();\n        });\n\n        return;\n      }\n\n      return callback(error);\n    }\n\n    var hasChunksIndex = false;\n    indexes.forEach(function (index) {\n      if (index.key) {\n        var keys = Object.keys(index.key);\n\n        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n          hasChunksIndex = true;\n        }\n      }\n    });\n\n    if (hasChunksIndex) {\n      callback();\n    } else {\n      index = {\n        files_id: 1,\n        n: 1\n      };\n      var indexOptions = getWriteOptions(_this);\n      indexOptions.background = false;\n      indexOptions.unique = true;\n\n      _this.chunks.createIndex(index, indexOptions, function (error) {\n        if (error) {\n          return callback(error);\n        }\n\n        callback();\n      });\n    }\n  });\n}\n/**\n * @ignore\n */\n\n\nfunction checkDone(_this, callback) {\n  if (_this.done) return true;\n\n  if (_this.state.streamEnd && _this.state.outstandingRequests === 0 && !_this.state.errored) {\n    // Set done so we dont' trigger duplicate createFilesDoc\n    _this.done = true; // Create a new files doc\n\n    var filesDoc = createFilesDoc(_this.id, _this.length, _this.chunkSizeBytes, _this.md5 && _this.md5.digest('hex'), _this.filename, _this.options.contentType, _this.options.aliases, _this.options.metadata);\n\n    if (checkAborted(_this, callback)) {\n      return false;\n    }\n\n    _this.files.insertOne(filesDoc, getWriteOptions(_this), function (error) {\n      if (error) {\n        return __handleError(_this, error, callback);\n      }\n\n      _this.emit('finish', filesDoc);\n    });\n\n    return true;\n  }\n\n  return false;\n}\n/**\n * @ignore\n */\n\n\nfunction checkIndexes(_this, callback) {\n  _this.files.findOne({}, {\n    _id: 1\n  }, function (error, doc) {\n    if (error) {\n      return callback(error);\n    }\n\n    if (doc) {\n      return callback();\n    }\n\n    _this.files.listIndexes().toArray(function (error, indexes) {\n      if (error) {\n        // Collection doesn't exist so create index\n        if (error.code === ERROR_NAMESPACE_NOT_FOUND) {\n          var index = {\n            filename: 1,\n            uploadDate: 1\n          };\n\n          _this.files.createIndex(index, {\n            background: false\n          }, function (error) {\n            if (error) {\n              return callback(error);\n            }\n\n            checkChunksIndex(_this, callback);\n          });\n\n          return;\n        }\n\n        return callback(error);\n      }\n\n      var hasFileIndex = false;\n      indexes.forEach(function (index) {\n        var keys = Object.keys(index.key);\n\n        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n          hasFileIndex = true;\n        }\n      });\n\n      if (hasFileIndex) {\n        checkChunksIndex(_this, callback);\n      } else {\n        index = {\n          filename: 1,\n          uploadDate: 1\n        };\n        var indexOptions = getWriteOptions(_this);\n        indexOptions.background = false;\n\n        _this.files.createIndex(index, indexOptions, function (error) {\n          if (error) {\n            return callback(error);\n          }\n\n          checkChunksIndex(_this, callback);\n        });\n      }\n    });\n  });\n}\n/**\n * @ignore\n */\n\n\nfunction createFilesDoc(_id, length, chunkSize, md5, filename, contentType, aliases, metadata) {\n  var ret = {\n    _id: _id,\n    length: length,\n    chunkSize: chunkSize,\n    uploadDate: new Date(),\n    filename: filename\n  };\n\n  if (md5) {\n    ret.md5 = md5;\n  }\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n/**\n * @ignore\n */\n\n\nfunction doWrite(_this, chunk, encoding, callback) {\n  if (checkAborted(_this, callback)) {\n    return false;\n  }\n\n  var inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  _this.length += inputBuf.length; // Input is small enough to fit in our buffer\n\n  if (_this.pos + inputBuf.length < _this.chunkSizeBytes) {\n    inputBuf.copy(_this.bufToStore, _this.pos);\n    _this.pos += inputBuf.length;\n    callback && callback(); // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n\n    return true;\n  } // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n\n\n  var inputBufRemaining = inputBuf.length;\n  var spaceRemaining = _this.chunkSizeBytes - _this.pos;\n  var numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  var outstandingRequests = 0;\n\n  while (inputBufRemaining > 0) {\n    var inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(_this.bufToStore, _this.pos, inputBufPos, inputBufPos + numToCopy);\n    _this.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n\n    if (spaceRemaining === 0) {\n      if (_this.md5) {\n        _this.md5.update(_this.bufToStore);\n      }\n\n      var doc = createChunkDoc(_this.id, _this.n, Buffer.from(_this.bufToStore));\n      ++_this.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (checkAborted(_this, callback)) {\n        return false;\n      }\n\n      _this.chunks.insertOne(doc, getWriteOptions(_this), function (error) {\n        if (error) {\n          return __handleError(_this, error);\n        }\n\n        --_this.state.outstandingRequests;\n        --outstandingRequests;\n\n        if (!outstandingRequests) {\n          _this.emit('drain', doc);\n\n          callback && callback();\n          checkDone(_this);\n        }\n      });\n\n      spaceRemaining = _this.chunkSizeBytes;\n      _this.pos = 0;\n      ++_this.n;\n    }\n\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  } // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n\n\n  return false;\n}\n/**\n * @ignore\n */\n\n\nfunction getWriteOptions(_this) {\n  var obj = {};\n\n  if (_this.options.writeConcern) {\n    obj.w = _this.options.writeConcern.w;\n    obj.wtimeout = _this.options.writeConcern.wtimeout;\n    obj.j = _this.options.writeConcern.j;\n  }\n\n  return obj;\n}\n/**\n * @ignore\n */\n\n\nfunction waitForIndexes(_this, callback) {\n  if (_this.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n\n  _this.bucket.once('index', function () {\n    callback(true);\n  });\n\n  return true;\n}\n/**\n * @ignore\n */\n\n\nfunction writeRemnant(_this, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (_this.pos === 0) {\n    return checkDone(_this, callback);\n  }\n\n  ++_this.state.outstandingRequests; // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n\n  var remnant = Buffer.alloc(_this.pos);\n\n  _this.bufToStore.copy(remnant, 0, 0, _this.pos);\n\n  if (_this.md5) {\n    _this.md5.update(remnant);\n  }\n\n  var doc = createChunkDoc(_this.id, _this.n, remnant); // If the stream was aborted, do not write remnant\n\n  if (checkAborted(_this, callback)) {\n    return false;\n  }\n\n  _this.chunks.insertOne(doc, getWriteOptions(_this), function (error) {\n    if (error) {\n      return __handleError(_this, error);\n    }\n\n    --_this.state.outstandingRequests;\n    checkDone(_this);\n  });\n}\n/**\n * @ignore\n */\n\n\nfunction checkAborted(_this, callback) {\n  if (_this.state.aborted) {\n    if (typeof callback === 'function') {\n      callback(new Error('this stream has been aborted'));\n    }\n\n    return true;\n  }\n\n  return false;\n}","map":null,"metadata":{},"sourceType":"script"}