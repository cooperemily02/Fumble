{"ast":null,"code":"'use strict';\n\nconst common = require('./common');\n\nconst BulkOperationBase = common.BulkOperationBase;\nconst Batch = common.Batch;\nconst bson = common.bson;\n\nconst utils = require('../utils');\n\nconst toError = utils.toError;\n/**\n * Add to internal list of Operations\n *\n * @ignore\n * @param {OrderedBulkOperation} bulkOperation\n * @param {number} docType number indicating the document type\n * @param {object} document\n * @return {OrderedBulkOperation}\n */\n\nfunction addToOperationsList(bulkOperation, docType, document) {\n  // Get the bsonSize\n  const bsonSize = bson.calculateObjectSize(document, {\n    checkKeys: false,\n    // Since we don't know what the user selected for BSON options here,\n    // err on the safe side, and check the size with ignoreUndefined: false.\n    ignoreUndefined: false\n  }); // Throw error if the doc is bigger than the max BSON size\n\n  if (bsonSize >= bulkOperation.s.maxBsonObjectSize) throw toError('document is larger than the maximum size ' + bulkOperation.s.maxBsonObjectSize); // Create a new batch object if we don't have a current one\n\n  if (bulkOperation.s.currentBatch == null) bulkOperation.s.currentBatch = new Batch(docType, bulkOperation.s.currentIndex);\n  const maxKeySize = bulkOperation.s.maxKeySize; // Check if we need to create a new batch\n\n  if ( // New batch if we exceed the max batch op size\n  bulkOperation.s.currentBatchSize + 1 >= bulkOperation.s.maxWriteBatchSize || // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n  // since we can't sent an empty batch\n  bulkOperation.s.currentBatchSize > 0 && bulkOperation.s.currentBatchSizeBytes + maxKeySize + bsonSize >= bulkOperation.s.maxBatchSizeBytes || // New batch if the new op does not have the same op type as the current batch\n  bulkOperation.s.currentBatch.batchType !== docType) {\n    // Save the batch to the execution stack\n    bulkOperation.s.batches.push(bulkOperation.s.currentBatch); // Create a new batch\n\n    bulkOperation.s.currentBatch = new Batch(docType, bulkOperation.s.currentIndex); // Reset the current size trackers\n\n    bulkOperation.s.currentBatchSize = 0;\n    bulkOperation.s.currentBatchSizeBytes = 0;\n  }\n\n  if (docType === common.INSERT) {\n    bulkOperation.s.bulkResult.insertedIds.push({\n      index: bulkOperation.s.currentIndex,\n      _id: document._id\n    });\n  } // We have an array of documents\n\n\n  if (Array.isArray(document)) {\n    throw toError('operation passed in cannot be an Array');\n  }\n\n  bulkOperation.s.currentBatch.originalIndexes.push(bulkOperation.s.currentIndex);\n  bulkOperation.s.currentBatch.operations.push(document);\n  bulkOperation.s.currentBatchSize += 1;\n  bulkOperation.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n  bulkOperation.s.currentIndex += 1; // Return bulkOperation\n\n  return bulkOperation;\n}\n/**\n * Create a new OrderedBulkOperation instance (INTERNAL TYPE, do not instantiate directly)\n * @class\n * @extends BulkOperationBase\n * @property {number} length Get the number of operations in the bulk.\n * @return {OrderedBulkOperation} a OrderedBulkOperation instance.\n */\n\n\nclass OrderedBulkOperation extends BulkOperationBase {\n  constructor(topology, collection, options) {\n    options = options || {};\n    options = Object.assign(options, {\n      addToOperationsList\n    });\n    super(topology, collection, options, true);\n  }\n\n}\n/**\n * Returns an unordered batch object\n * @ignore\n */\n\n\nfunction initializeOrderedBulkOp(topology, collection, options) {\n  return new OrderedBulkOperation(topology, collection, options);\n}\n\ninitializeOrderedBulkOp.OrderedBulkOperation = OrderedBulkOperation;\nmodule.exports = initializeOrderedBulkOp;\nmodule.exports.Bulk = OrderedBulkOperation;","map":null,"metadata":{},"sourceType":"script"}