{"ast":null,"code":"'use strict';\n\nvar Emitter = require('events').EventEmitter;\n\nvar GridFSBucketReadStream = require('./download');\n\nvar GridFSBucketWriteStream = require('./upload');\n\nvar shallowClone = require('../utils').shallowClone;\n\nvar toError = require('../utils').toError;\n\nvar util = require('util');\n\nvar executeLegacyOperation = require('../utils').executeLegacyOperation;\n\nvar DEFAULT_GRIDFS_BUCKET_OPTIONS = {\n  bucketName: 'fs',\n  chunkSizeBytes: 255 * 1024\n};\nmodule.exports = GridFSBucket;\n/**\n * Constructor for a streaming GridFS interface\n * @class\n * @extends external:EventEmitter\n * @param {Db} db A db handle\n * @param {object} [options] Optional settings.\n * @param {string} [options.bucketName=\"fs\"] The 'files' and 'chunks' collections will be prefixed with the bucket name followed by a dot.\n * @param {number} [options.chunkSizeBytes=255 * 1024] Number of bytes stored in each chunk. Defaults to 255KB\n * @param {object} [options.writeConcern] Optional write concern to be passed to write operations, for instance `{ w: 1 }`\n * @param {object} [options.readPreference] Optional read preference to be passed to read operations\n * @fires GridFSBucketWriteStream#index\n */\n\nfunction GridFSBucket(db, options) {\n  Emitter.apply(this);\n  this.setMaxListeners(0);\n\n  if (options && typeof options === 'object') {\n    options = shallowClone(options);\n    var keys = Object.keys(DEFAULT_GRIDFS_BUCKET_OPTIONS);\n\n    for (var i = 0; i < keys.length; ++i) {\n      if (!options[keys[i]]) {\n        options[keys[i]] = DEFAULT_GRIDFS_BUCKET_OPTIONS[keys[i]];\n      }\n    }\n  } else {\n    options = DEFAULT_GRIDFS_BUCKET_OPTIONS;\n  }\n\n  this.s = {\n    db: db,\n    options: options,\n    _chunksCollection: db.collection(options.bucketName + '.chunks'),\n    _filesCollection: db.collection(options.bucketName + '.files'),\n    checkedIndexes: false,\n    calledOpenUploadStream: false,\n    promiseLibrary: db.s.promiseLibrary || Promise\n  };\n}\n\nutil.inherits(GridFSBucket, Emitter);\n/**\n * When the first call to openUploadStream is made, the upload stream will\n * check to see if it needs to create the proper indexes on the chunks and\n * files collections. This event is fired either when 1) it determines that\n * no index creation is necessary, 2) when it successfully creates the\n * necessary indexes.\n *\n * @event GridFSBucket#index\n * @type {Error}\n */\n\n/**\n * Returns a writable stream (GridFSBucketWriteStream) for writing\n * buffers to GridFS. The stream's 'id' property contains the resulting\n * file's id.\n * @method\n * @param {string} filename The value of the 'filename' key in the files doc\n * @param {object} [options] Optional settings.\n * @param {number} [options.chunkSizeBytes] Optional overwrite this bucket's chunkSizeBytes for this file\n * @param {object} [options.metadata] Optional object to store in the file document's `metadata` field\n * @param {string} [options.contentType] Optional string to store in the file document's `contentType` field\n * @param {array} [options.aliases] Optional array of strings to store in the file document's `aliases` field\n * @param {boolean} [options.disableMD5=false] If true, disables adding an md5 field to file data\n * @return {GridFSBucketWriteStream}\n */\n\nGridFSBucket.prototype.openUploadStream = function (filename, options) {\n  if (options) {\n    options = shallowClone(options);\n  } else {\n    options = {};\n  }\n\n  if (!options.chunkSizeBytes) {\n    options.chunkSizeBytes = this.s.options.chunkSizeBytes;\n  }\n\n  return new GridFSBucketWriteStream(this, filename, options);\n};\n/**\n * Returns a writable stream (GridFSBucketWriteStream) for writing\n * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n * file's id.\n * @method\n * @param {string|number|object} id A custom id used to identify the file\n * @param {string} filename The value of the 'filename' key in the files doc\n * @param {object} [options] Optional settings.\n * @param {number} [options.chunkSizeBytes] Optional overwrite this bucket's chunkSizeBytes for this file\n * @param {object} [options.metadata] Optional object to store in the file document's `metadata` field\n * @param {string} [options.contentType] Optional string to store in the file document's `contentType` field\n * @param {array} [options.aliases] Optional array of strings to store in the file document's `aliases` field\n * @param {boolean} [options.disableMD5=false] If true, disables adding an md5 field to file data\n * @return {GridFSBucketWriteStream}\n */\n\n\nGridFSBucket.prototype.openUploadStreamWithId = function (id, filename, options) {\n  if (options) {\n    options = shallowClone(options);\n  } else {\n    options = {};\n  }\n\n  if (!options.chunkSizeBytes) {\n    options.chunkSizeBytes = this.s.options.chunkSizeBytes;\n  }\n\n  options.id = id;\n  return new GridFSBucketWriteStream(this, filename, options);\n};\n/**\n * Returns a readable stream (GridFSBucketReadStream) for streaming file\n * data from GridFS.\n * @method\n * @param {ObjectId} id The id of the file doc\n * @param {Object} [options] Optional settings.\n * @param {Number} [options.start] Optional 0-based offset in bytes to start streaming from\n * @param {Number} [options.end] Optional 0-based offset in bytes to stop streaming before\n * @return {GridFSBucketReadStream}\n */\n\n\nGridFSBucket.prototype.openDownloadStream = function (id, options) {\n  var filter = {\n    _id: id\n  };\n  options = {\n    start: options && options.start,\n    end: options && options.end\n  };\n  return new GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, filter, options);\n};\n/**\n * Deletes a file with the given id\n * @method\n * @param {ObjectId} id The id of the file doc\n * @param {GridFSBucket~errorCallback} [callback]\n */\n\n\nGridFSBucket.prototype.delete = function (id, callback) {\n  return executeLegacyOperation(this.s.db.s.topology, _delete, [this, id, callback], {\n    skipSessions: true\n  });\n};\n/**\n * @ignore\n */\n\n\nfunction _delete(_this, id, callback) {\n  _this.s._filesCollection.deleteOne({\n    _id: id\n  }, function (error, res) {\n    if (error) {\n      return callback(error);\n    }\n\n    _this.s._chunksCollection.deleteMany({\n      files_id: id\n    }, function (error) {\n      if (error) {\n        return callback(error);\n      } // Delete orphaned chunks before returning FileNotFound\n\n\n      if (!res.result.n) {\n        var errmsg = 'FileNotFound: no file with id ' + id + ' found';\n        return callback(new Error(errmsg));\n      }\n\n      callback();\n    });\n  });\n}\n/**\n * Convenience wrapper around find on the files collection\n * @method\n * @param {Object} filter\n * @param {Object} [options] Optional settings for cursor\n * @param {number} [options.batchSize=1000] The number of documents to return per batch. See {@link https://docs.mongodb.com/manual/reference/command/find|find command documentation}.\n * @param {number} [options.limit] Optional limit for cursor\n * @param {number} [options.maxTimeMS] Optional maxTimeMS for cursor\n * @param {boolean} [options.noCursorTimeout] Optionally set cursor's `noCursorTimeout` flag\n * @param {number} [options.skip] Optional skip for cursor\n * @param {object} [options.sort] Optional sort for cursor\n * @return {Cursor}\n */\n\n\nGridFSBucket.prototype.find = function (filter, options) {\n  filter = filter || {};\n  options = options || {};\n\n  var cursor = this.s._filesCollection.find(filter);\n\n  if (options.batchSize != null) {\n    cursor.batchSize(options.batchSize);\n  }\n\n  if (options.limit != null) {\n    cursor.limit(options.limit);\n  }\n\n  if (options.maxTimeMS != null) {\n    cursor.maxTimeMS(options.maxTimeMS);\n  }\n\n  if (options.noCursorTimeout != null) {\n    cursor.addCursorFlag('noCursorTimeout', options.noCursorTimeout);\n  }\n\n  if (options.skip != null) {\n    cursor.skip(options.skip);\n  }\n\n  if (options.sort != null) {\n    cursor.sort(options.sort);\n  }\n\n  return cursor;\n};\n/**\n * Returns a readable stream (GridFSBucketReadStream) for streaming the\n * file with the given name from GridFS. If there are multiple files with\n * the same name, this will stream the most recent file with the given name\n * (as determined by the `uploadDate` field). You can set the `revision`\n * option to change this behavior.\n * @method\n * @param {String} filename The name of the file to stream\n * @param {Object} [options] Optional settings\n * @param {number} [options.revision=-1] The revision number relative to the oldest file with the given filename. 0 gets you the oldest file, 1 gets you the 2nd oldest, -1 gets you the newest.\n * @param {Number} [options.start] Optional 0-based offset in bytes to start streaming from\n * @param {Number} [options.end] Optional 0-based offset in bytes to stop streaming before\n * @return {GridFSBucketReadStream}\n */\n\n\nGridFSBucket.prototype.openDownloadStreamByName = function (filename, options) {\n  var sort = {\n    uploadDate: -1\n  };\n  var skip = null;\n\n  if (options && options.revision != null) {\n    if (options.revision >= 0) {\n      sort = {\n        uploadDate: 1\n      };\n      skip = options.revision;\n    } else {\n      skip = -options.revision - 1;\n    }\n  }\n\n  var filter = {\n    filename: filename\n  };\n  options = {\n    sort: sort,\n    skip: skip,\n    start: options && options.start,\n    end: options && options.end\n  };\n  return new GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, filter, options);\n};\n/**\n * Renames the file with the given _id to the given string\n * @method\n * @param {ObjectId} id the id of the file to rename\n * @param {String} filename new name for the file\n * @param {GridFSBucket~errorCallback} [callback]\n */\n\n\nGridFSBucket.prototype.rename = function (id, filename, callback) {\n  return executeLegacyOperation(this.s.db.s.topology, _rename, [this, id, filename, callback], {\n    skipSessions: true\n  });\n};\n/**\n * @ignore\n */\n\n\nfunction _rename(_this, id, filename, callback) {\n  var filter = {\n    _id: id\n  };\n  var update = {\n    $set: {\n      filename: filename\n    }\n  };\n\n  _this.s._filesCollection.updateOne(filter, update, function (error, res) {\n    if (error) {\n      return callback(error);\n    }\n\n    if (!res.result.n) {\n      return callback(toError('File with id ' + id + ' not found'));\n    }\n\n    callback();\n  });\n}\n/**\n * Removes this bucket's files collection, followed by its chunks collection.\n * @method\n * @param {GridFSBucket~errorCallback} [callback]\n */\n\n\nGridFSBucket.prototype.drop = function (callback) {\n  return executeLegacyOperation(this.s.db.s.topology, _drop, [this, callback], {\n    skipSessions: true\n  });\n};\n/**\n * Return the db logger\n * @method\n * @return {Logger} return the db logger\n * @ignore\n */\n\n\nGridFSBucket.prototype.getLogger = function () {\n  return this.s.db.s.logger;\n};\n/**\n * @ignore\n */\n\n\nfunction _drop(_this, callback) {\n  _this.s._filesCollection.drop(function (error) {\n    if (error) {\n      return callback(error);\n    }\n\n    _this.s._chunksCollection.drop(function (error) {\n      if (error) {\n        return callback(error);\n      }\n\n      return callback();\n    });\n  });\n}\n/**\n * Callback format for all GridFSBucket methods that can accept a callback.\n * @callback GridFSBucket~errorCallback\n * @param {MongoError|undefined} error If present, an error instance representing any errors that occurred\n * @param {*} result If present, a returned result for the method\n */","map":null,"metadata":{},"sourceType":"script"}